{"cells": [{"metadata": {}, "id": "brief-diploma", "cell_type": "code", "source": "pwd", "execution_count": 1, "outputs": [{"output_type": "execute_result", "execution_count": 1, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "id": "240ba219", "cell_type": "markdown", "source": "# Inserting necessary libraries"}, {"metadata": {}, "id": "1880001b", "cell_type": "code", "source": "import numpy as np#used for numerical analysis\nimport tensorflow #open source used for both ML and DL for computation\nfrom tensorflow.keras.models import Sequential #it is a plain stack of layers\nfrom tensorflow.keras import layers #A layer consists of a tensor-in tensor-out computation function\n#Dense layer is the regular deeply connected neural network layer\nfrom tensorflow.keras.layers import Dense,Flatten\n#Faltten-used fot flattening the input or change the dimension\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D #Convolutional layer\n#MaxPooling2D-for downsampling the image\nfrom keras.preprocessing.image import ImageDataGenerator", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Using TensorFlow backend.\n", "name": "stderr"}]}, {"metadata": {}, "id": "4de4433a", "cell_type": "code", "source": "tensorflow.__version__", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "'2.3.0'"}, "metadata": {}}]}, {"metadata": {}, "id": "9266ab12", "cell_type": "code", "source": "tensorflow.keras.__version__", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "'2.4.0'"}, "metadata": {}}]}, {"metadata": {}, "id": "8755ebc6", "cell_type": "markdown", "source": "# Image Data Augumentation"}, {"metadata": {}, "id": "2849cdf2", "cell_type": "code", "source": "#setting parameter for Image Data agumentation to the training data\ntrain_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n#Image Data agumentation to the testing data\ntest_datagen=ImageDataGenerator(rescale=1./255)", "execution_count": 11, "outputs": []}, {"metadata": {}, "id": "30cc8750", "cell_type": "markdown", "source": "# Loading our data and performing Data Augumentation"}, {"metadata": {}, "id": "commercial-audio", "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\nif os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n    endpoint_d6c4aa54985d4755b8f33ab78c4fe1f0 = 'https://s3.us.cloud-object-storage.appdomain.cloud'\nelse:\n    endpoint_d6c4aa54985d4755b8f33ab78c4fe1f0 = 'https://s3.private.us.cloud-object-storage.appdomain.cloud'\n\nclient_d6c4aa54985d4755b8f33ab78c4fe1f0 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='k1ICcSyubCBRkuMzExqnzzFWzxk_udmE35sGXYL5wkNc',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url=endpoint_d6c4aa54985d4755b8f33ab78c4fe1f0)\n\nstreaming_body_1 = client_d6c4aa54985d4755b8f33ab78c4fe1f0.get_object(Bucket='naturaldisaster-donotdelete-pr-aj3prbxphtojo0', Key='dataset.zip')['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 12, "outputs": []}, {"metadata": {}, "id": "lyric-seventh", "cell_type": "code", "source": "from io import BytesIO\nimport zipfile\nunzip = zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\nfile_paths = unzip.namelist()\nfor path in file_paths:\n    unzip.extract(path)", "execution_count": 13, "outputs": []}, {"metadata": {}, "id": "dense-worcester", "cell_type": "code", "source": "pwd", "execution_count": 15, "outputs": [{"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "id": "humanitarian-heavy", "cell_type": "code", "source": "import os\nfilenames = os.listdir('/home/wsuser/work/dataset/train_set')", "execution_count": 16, "outputs": []}, {"metadata": {}, "id": "7504ebdc", "cell_type": "code", "source": "#performing data agumentation to train data\nx_train = train_datagen.flow_from_directory(r'/home/wsuser/work/dataset/train_set',target_size=(64, 64),batch_size=5,\n                                            color_mode='rgb',class_mode='categorical')\n#performing data agumentation to test data\nx_test = test_datagen.flow_from_directory(r'/home/wsuser/work/dataset/test_set',target_size=(64, 64),batch_size=5,\n                                            color_mode='rgb',class_mode='categorical')", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "Found 742 images belonging to 4 classes.\nFound 198 images belonging to 4 classes.\n", "name": "stdout"}]}, {"metadata": {}, "id": "23e9b190", "cell_type": "code", "source": "print(x_train.class_indices)#checking the number of classes", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "{'Cyclone': 0, 'Earthquake': 1, 'Flood': 2, 'Wildfire': 3}\n", "name": "stdout"}]}, {"metadata": {}, "id": "c5d1bb8a", "cell_type": "code", "source": "print(x_test.class_indices)#checking the number of classes", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "{'Cyclone1': 0, 'Earthquake1': 1, 'Flood1': 2, 'Wildfire1': 3}\n", "name": "stdout"}]}, {"metadata": {}, "id": "04edbb32", "cell_type": "code", "source": "from collections import Counter as c\nc(x_train .labels)", "execution_count": 20, "outputs": [{"output_type": "execute_result", "execution_count": 20, "data": {"text/plain": "Counter({0: 220, 1: 156, 2: 198, 3: 168})"}, "metadata": {}}]}, {"metadata": {}, "id": "b844dc41", "cell_type": "markdown", "source": "# Creating the Model"}, {"metadata": {}, "id": "f26121f6", "cell_type": "code", "source": "# Initializing the CNN\nclassifier = Sequential()\n\n# First convolution layer and poolingo\nclassifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2, 2)))\nclassifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n# Second convolution layer and pooling\nclassifier.add(Conv2D(32, (3, 3), activation='relu'))\n# input_shape is going to be the pooled feature maps from the previous convolution layer\nclassifier.add(MaxPooling2D(pool_size=(2, 2)))\nclassifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n\n# Flattening the layers\nclassifier.add(Flatten())\n\n# Adding a fully connected layer\nclassifier.add(Dense(units=128, activation='relu'))\nclassifier.add(Dense(units=4, activation='softmax')) # softmax for more than 2", "execution_count": 21, "outputs": []}, {"metadata": {}, "id": "a68921cc", "cell_type": "code", "source": "classifier.summary()#summary of our model", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 62, 62, 32)        896       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 27, 27, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 11, 11, 32)        9248      \n_________________________________________________________________\nflatten (Flatten)            (None, 3872)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               495744    \n_________________________________________________________________\ndense_1 (Dense)              (None, 4)                 516       \n=================================================================\nTotal params: 524,900\nTrainable params: 524,900\nNon-trainable params: 0\n_________________________________________________________________\n", "name": "stdout"}]}, {"metadata": {}, "id": "19c3e5d7", "cell_type": "markdown", "source": "# Compiling the Model"}, {"metadata": {}, "id": "02810f3e", "cell_type": "code", "source": "# Compiling the CNN\n# categorical_crossentropy for more than 2\nclassifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])", "execution_count": 23, "outputs": []}, {"metadata": {}, "id": "5d86c2c1", "cell_type": "markdown", "source": "# Fitting the Model"}, {"metadata": {}, "id": "08aef824", "cell_type": "code", "source": "classifier.fit_generator(\n        generator=x_train,steps_per_epoch = len(x_train),\n        epochs=20, validation_data=x_test,validation_steps = len(x_test))# No of images in test set", "execution_count": 24, "outputs": [{"output_type": "stream", "text": "WARNING:tensorflow:From <ipython-input-24-386df932e001>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use Model.fit, which supports generators.\nEpoch 1/20\n149/149 [==============================] - 32s 217ms/step - loss: 1.1916 - accuracy: 0.4582 - val_loss: 1.0800 - val_accuracy: 0.5505\nEpoch 2/20\n149/149 [==============================] - 32s 213ms/step - loss: 1.0074 - accuracy: 0.5876 - val_loss: 1.1755 - val_accuracy: 0.5505\nEpoch 3/20\n149/149 [==============================] - 31s 211ms/step - loss: 0.8887 - accuracy: 0.6146 - val_loss: 0.9522 - val_accuracy: 0.6465\nEpoch 4/20\n149/149 [==============================] - 31s 210ms/step - loss: 0.8046 - accuracy: 0.6685 - val_loss: 0.8259 - val_accuracy: 0.6566\nEpoch 5/20\n149/149 [==============================] - 31s 208ms/step - loss: 0.7213 - accuracy: 0.7291 - val_loss: 1.2338 - val_accuracy: 0.5556\nEpoch 6/20\n149/149 [==============================] - 31s 210ms/step - loss: 0.6916 - accuracy: 0.7237 - val_loss: 0.7315 - val_accuracy: 0.7273\nEpoch 7/20\n149/149 [==============================] - 31s 208ms/step - loss: 0.6020 - accuracy: 0.7588 - val_loss: 0.7086 - val_accuracy: 0.7323\nEpoch 8/20\n149/149 [==============================] - 31s 206ms/step - loss: 0.6151 - accuracy: 0.7615 - val_loss: 0.7183 - val_accuracy: 0.7222\nEpoch 9/20\n149/149 [==============================] - 31s 209ms/step - loss: 0.5500 - accuracy: 0.7776 - val_loss: 0.6641 - val_accuracy: 0.7525\nEpoch 10/20\n149/149 [==============================] - 31s 209ms/step - loss: 0.4813 - accuracy: 0.8167 - val_loss: 0.8024 - val_accuracy: 0.7020\nEpoch 11/20\n149/149 [==============================] - 31s 207ms/step - loss: 0.4713 - accuracy: 0.8248 - val_loss: 0.7519 - val_accuracy: 0.7778\nEpoch 12/20\n149/149 [==============================] - 31s 208ms/step - loss: 0.4306 - accuracy: 0.8518 - val_loss: 0.6618 - val_accuracy: 0.7828\nEpoch 13/20\n149/149 [==============================] - 31s 209ms/step - loss: 0.4416 - accuracy: 0.8261 - val_loss: 0.7920 - val_accuracy: 0.7677\nEpoch 14/20\n149/149 [==============================] - 30s 199ms/step - loss: 0.4147 - accuracy: 0.8383 - val_loss: 0.8642 - val_accuracy: 0.7475\nEpoch 15/20\n149/149 [==============================] - 31s 209ms/step - loss: 0.3917 - accuracy: 0.8531 - val_loss: 0.8662 - val_accuracy: 0.7879\nEpoch 16/20\n149/149 [==============================] - 31s 208ms/step - loss: 0.3508 - accuracy: 0.8652 - val_loss: 1.2722 - val_accuracy: 0.7172\nEpoch 17/20\n149/149 [==============================] - 31s 208ms/step - loss: 0.3357 - accuracy: 0.8585 - val_loss: 0.9878 - val_accuracy: 0.7374\nEpoch 18/20\n149/149 [==============================] - 31s 207ms/step - loss: 0.3271 - accuracy: 0.8747 - val_loss: 1.2934 - val_accuracy: 0.6818\nEpoch 19/20\n149/149 [==============================] - 31s 209ms/step - loss: 0.3405 - accuracy: 0.8922 - val_loss: 1.1338 - val_accuracy: 0.7071\nEpoch 20/20\n149/149 [==============================] - 31s 208ms/step - loss: 0.3629 - accuracy: 0.8504 - val_loss: 0.7408 - val_accuracy: 0.7980\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 24, "data": {"text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f6cba70aeb0>"}, "metadata": {}}]}, {"metadata": {}, "id": "b7165784", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "00fa516f", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "19bda4e4", "cell_type": "markdown", "source": "# Saving the Model"}, {"metadata": {}, "id": "fbb50055", "cell_type": "code", "source": "# Save the model\nclassifier.save('disaster.h5')", "execution_count": 25, "outputs": []}, {"metadata": {}, "id": "italian-typing", "cell_type": "code", "source": "!tar -zcvf natural-disaster-classifier_new.tgz disaster.h5", "execution_count": 32, "outputs": [{"output_type": "stream", "text": "disaster.h5\r\n", "name": "stdout"}]}, {"metadata": {}, "id": "vietnamese-restaurant", "cell_type": "code", "source": "ls -1", "execution_count": 33, "outputs": [{"output_type": "stream", "text": "\u001b[0m\u001b[01;34mdataset\u001b[0m/\r\ndisaster.h5\r\nmodel-bw.json\r\nnatural-disaster-classifier_new.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "id": "black-advocate", "cell_type": "code", "source": "#To save our file in machine learning repository we have to import library\n!pip install watson-machine-learning-client --upgrade", "execution_count": 34, "outputs": [{"output_type": "stream", "text": "Collecting watson-machine-learning-client\n  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 538 kB 26.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (2.25.1)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (0.3.3)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (2.7.0)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (1.26.6)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (0.8.9)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (1.17.46)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (2021.10.8)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (4.59.0)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (1.2.4)\nRequirement already satisfied: botocore<1.21.0,>=1.20.46 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from boto3->watson-machine-learning-client) (1.20.88)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from boto3->watson-machine-learning-client) (0.3.6)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from botocore<1.21.0,>=1.20.46->boto3->watson-machine-learning-client) (2.8.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.46->boto3->watson-machine-learning-client) (1.15.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.7.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.7.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.7.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.7.0)\nRequirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cos-sdk-core==2.7.0->ibm-cos-sdk->watson-machine-learning-client) (0.15.2)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->watson-machine-learning-client) (2.8)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->watson-machine-learning-client) (3.0.4)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas->watson-machine-learning-client) (2021.1)\nRequirement already satisfied: numpy>=1.16.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas->watson-machine-learning-client) (1.18.5)\nInstalling collected packages: watson-machine-learning-client\nSuccessfully installed watson-machine-learning-client-1.0.391\n", "name": "stdout"}]}, {"metadata": {}, "id": "behavioral-russell", "cell_type": "code", "source": "#Replace the credentials that you got from watson Machine Learning Service\nfrom ibm_watson_machine_learning import APIClient\nwml_credentials = {\n                   \"url\":\"https://us-south.ml.cloud.ibm.com\",\n                   \"apikey\":\"msSVl1ItE8WsNE-qN6DCjR__9IvD8xCx3U4Py3Oq2-rk\"\n                  }\nclient=APIClient(wml_credentials)", "execution_count": 36, "outputs": []}, {"metadata": {}, "id": "injured-upgrade", "cell_type": "code", "source": "client = APIClient(wml_credentials)", "execution_count": 37, "outputs": []}, {"metadata": {}, "id": "alpha-publisher", "cell_type": "code", "source": "def guid_from_space_name(client, space_name):\n    space = client.spaces.get_details()\n    #print(space)\n    return(next(item for item in space['resources'] if item['entity'][\"name\"] == space_name)['metadata']['id'])", "execution_count": 38, "outputs": []}, {"metadata": {}, "id": "following-brunswick", "cell_type": "code", "source": "space_uid = guid_from_space_name(client, 'naturaldisaster1')\nprint(\"Space UID = \" + space_uid)", "execution_count": 39, "outputs": [{"output_type": "stream", "text": "Space UID = 69d9ecd9-c6a9-48d3-856e-baf6ea02a14d\n", "name": "stdout"}]}, {"metadata": {}, "id": "foreign-parameter", "cell_type": "code", "source": "client.set.default_space(space_uid)", "execution_count": 40, "outputs": [{"output_type": "execute_result", "execution_count": 40, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {}, "id": "skilled-captain", "cell_type": "code", "source": "client.software_specifications.list()", "execution_count": 41, "outputs": [{"output_type": "stream", "text": "-----------------------------  ------------------------------------  ----\nNAME                           ASSET_ID                              TYPE\ndefault_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\npytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\nscikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\nspark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\nai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\nshiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\ntensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\npytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\ntensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\nscikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\ndefault_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\npytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\ntensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\ntensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\ndo_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\nautoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\ntensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\npytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\nspark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\npytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\nspark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\nspark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\nxgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\npytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\nautoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\nspark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\nxgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\npytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\nautoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\nspark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\nspark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\nautoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\nspss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\ncuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\nautoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\npytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\nspark-mllib_2.3-r_3.6          6586b9e3-ccd6-4f92-900f-0f8cb2bd6f0c  base\ntensorflow_2.4-py3.7           65e171d7-72d1-55d9-8ebb-f813d620c9bb  base\nspss-modeler_18.2              687eddc9-028a-4117-b9dd-e57b36f1efa5  base\npytorch-onnx_1.2-py3.6         692a6a4d-2c4d-45ff-a1ed-b167ee55469a  base\ndo_12.9                        75a3a4b0-6aa0-41b3-a618-48b1f56332a6  base\nspark-mllib_2.3-scala_2.11     7963efe5-bbec-417e-92cf-0574e21b4e8d  base\nspark-mllib_2.4-py37           7abc992b-b685-532b-a122-a396a3cdbaab  base\ncaffe_1.0-py3.6                7bb3dbe2-da6e-4145-918d-b6d84aa93b6b  base\npytorch-onnx_1.7-py3.7         812c6631-42b7-5613-982b-02098e6c909c  base\ncuda-py3.6                     82c79ece-4d12-40e6-8787-a7b9e0f62770  base\ntensorflow_1.15-py3.6-horovod  8964680e-d5e4-5bb8-919b-8342c6c0dfd8  base\nhybrid_0.1                     8c1a58c6-62b5-4dc4-987a-df751c2756b6  base\npytorch-onnx_1.3-py3.7         8d5d8a87-a912-54cf-81ec-3914adaa988d  base\ncaffe-ibm_1.0-py3.6            8d863266-7927-4d1e-97d7-56a7f4c0a19b  base\n-----------------------------  ------------------------------------  ----\nNote: Only first 50 records were displayed. To display more use 'limit' parameter.\n", "name": "stdout"}]}, {"metadata": {}, "id": "pressed-passion", "cell_type": "code", "source": "software_spec_uid = client.software_specifications.get_uid_by_name(\"tensorflow_1.15-py3.6\")\nsoftware_spec_uid", "execution_count": 42, "outputs": [{"output_type": "execute_result", "execution_count": 42, "data": {"text/plain": "'2b73a275-7cbf-420b-a912-eae7f436e0bc'"}, "metadata": {}}]}, {"metadata": {}, "id": "appropriate-comparative", "cell_type": "code", "source": "model_details = client.repository.store_model(model='natural-disaster-classifier_new.tgz',meta_props={\nclient.repository.ModelMetaNames.NAME:\"CNN\",\nclient.repository.ModelMetaNames.TYPE:\"keras_2.2.4\",\nclient.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid}\n                                             )\nmodel_id = client.repository.get_model_uid(model_details)", "execution_count": 50, "outputs": [{"output_type": "stream", "text": "Note: Warnings!! :  Model type keras_2.2.4 is deprecated. We recommend you use a supported model type. See Supported Frameworks https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/pm_service_supported_frameworks.html\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "model_id", "execution_count": 51, "outputs": [{"output_type": "execute_result", "execution_count": 51, "data": {"text/plain": "'cf70fd82-d094-4cfa-b7b5-f876d3db13f3'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.repository.download(model_id, 'my_model1.tar.gz')", "execution_count": 53, "outputs": [{"output_type": "stream", "text": "Successfully saved model content to file: 'my_model1.tar.gz'\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 53, "data": {"text/plain": "'/home/wsuser/work/my_model1.tar.gz'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "6f925f86", "cell_type": "code", "source": "model_json = classifier.to_json()\nwith open(\"model-bw.json\", \"w\") as json_file:\n    json_file.write(model_json)", "execution_count": 54, "outputs": []}, {"metadata": {}, "id": "60affc33", "cell_type": "markdown", "source": "# Predicting Results"}, {"metadata": {}, "id": "f05b455b", "cell_type": "code", "source": "from tensorflow.keras.models import load_model\nfrom keras.preprocessing import image\nmodel = load_model(\"disaster.h5\") #loading the model for testing", "execution_count": 55, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nstreaming_body_2 = client_d6c4aa54985d4755b8f33ab78c4fe1f0.get_object(Bucket='naturaldisaster-donotdelete-pr-aj3prbxphtojo0', Key='cyclone.jpg')['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 61, "outputs": []}, {"metadata": {}, "id": "2770305b", "cell_type": "code", "source": "\nstreaming_body_3 = client_d6c4aa54985d4755b8f33ab78c4fe1f0.get_object(Bucket='naturaldisaster-donotdelete-pr-aj3prbxphtojo0', Key='cyclone.jpg')['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nimg = image.load_img(streaming_body_3,target_size = (64,64))#loading of the image\\n", "execution_count": 65, "outputs": [{"output_type": "error", "ename": "TypeError", "evalue": "expected str, bytes or os.PathLike object, not StreamingBody", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-65-86cf45267c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# pandas documentation: http://pandas.pydata.org/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreaming_body_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#loading of the image\\n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m   \"\"\"\n\u001b[0;32m--> 300\u001b[0;31m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0m\u001b[1;32m    301\u001b[0m                         target_size=target_size, interpolation=interpolation)\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not StreamingBody"]}]}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\nx = image.img_to_array(img)\nx = np.expand_dims(x,axis = 0)", "execution_count": 66, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pred = model.predict_classes(x)", "execution_count": 68, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pred[0]", "execution_count": 69, "outputs": [{"output_type": "execute_result", "execution_count": 69, "data": {"text/plain": "0"}, "metadata": {}}]}, {"metadata": {}, "id": "c1d885cc", "cell_type": "code", "source": "index=['Cyclone','Earthquake','Flood','Wildfire']\nresult=str(index[pred[0]])\nresult", "execution_count": 70, "outputs": [{"output_type": "execute_result", "execution_count": 70, "data": {"text/plain": "'Cyclone'"}, "metadata": {}}]}, {"metadata": {}, "id": "f77d2631", "cell_type": "code", "source": "!pip install jupyterthemes as jt", "execution_count": 22, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Collecting jupyterthemes\n  Using cached jupyterthemes-0.20.0-py2.py3-none-any.whl (7.0 MB)\n"}, {"name": "stderr", "output_type": "stream", "text": "ERROR: Could not find a version that satisfies the requirement as\nERROR: No matching distribution found for as\n"}]}, {"metadata": {}, "id": "b84e2478", "cell_type": "code", "source": "!jt -t monokai", "execution_count": 23, "outputs": [{"name": "stderr", "output_type": "stream", "text": "'jt' is not recognized as an internal or external command,\noperable program or batch file.\n"}]}, {"metadata": {}, "id": "01f4196f", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.8", "language": "python"}, "language_info": {"name": "python", "version": "3.8.11", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 5}